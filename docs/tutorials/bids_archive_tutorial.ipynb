{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook teaches how to use the BIDS Archive & BIDS incremental classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "There are a few terms that are important to understand before starting to use BIDS Archive.\n",
    "\n",
    "## BIDS Entities\n",
    "\n",
    "BIDS Entities, referred to later as just 'entities', represent metadata about files in the archive. You may already be familiar with common ones, like 'subject', 'task', and 'run'. \n",
    "\n",
    "Most entities are used in a key-value form and have their name and value present wherever they are used. They have three main representations. The first is the entity itself, the one-word, all lowercase string (e.g., 'subject'). The second is the entity's name, which may be sevearl words (e.g., 'Contrast Enhancing Agent' is the name for the 'ceagent' entity). The third is the entity's key, which is typically shorter and used in file names (e.g., 'ce' for the 'ceagent' entity). A few entities and their multiple representations are shown in the table below:\n",
    "\n",
    "| Entity | Name | Key |\n",
    "| --- | --- | --- |\n",
    "| subject | Subject | sub |\n",
    "| session | Session | ses |\n",
    "| run | Run | run |\n",
    "| ceagent | Contrast Enhancing Agent | ce |\n",
    "\n",
    "Some entities aren't used in key-value format, and have only one representation. Examples include 'datatype' (e.g., 'func' or 'anat'), 'extension' (e.g., '.nii', '.nii.gz', or '.json'), and 'suffix' (e.g., 'bold'). See the table below for how these can appear in file naming and archive organization.\n",
    "\n",
    "Together, these entities provide a unique and consistent way to name files and organize the BIDS dataset.\n",
    "\n",
    "#### Exercise: What entities are present in the path `sub-01/func/sub-01_task-languageproduction_run-01_bold.nii.gz`, and what are the entity values? \n",
    "\n",
    "##### Answer: \n",
    "| Entity Name | Value |\n",
    "|---          | ---   |\n",
    "| subject | 01 |\n",
    "| datatype | func |\n",
    "| task | languageproduction |\n",
    "| run | 01 |\n",
    "| suffix | bold |\n",
    "| extension | .nii.gz|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Archive: Opening Existing Dataset\n",
    "\n",
    "Objective: Learn how to create a BIDS Archive pointing to a specific dataset on disk.\n",
    "\n",
    "Procedure:\n",
    "1. Download a small, sample dataset from OpenNeuro to use with `BidsArchive`.\n",
    "2. Open the dataset using `BidsArchive` and print out some summary data about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Add rtCommon to the path \"\"\"\n",
    "import os\n",
    "import sys\n",
    "currPath = os.path.dirname(os.path.realpath(os.getcwd())) # docs\n",
    "rootPath = os.path.dirname(currPath) # project root\n",
    "sys.path.append(rootPath)\n",
    "\n",
    "\n",
    "\"\"\" Download the dataset \"\"\"\n",
    "import subprocess\n",
    "\n",
    "# https://openneuro.org/datasets/ds002014/versions/1.0.1/download -- <40MB dataset\n",
    "TARGET_DIR = 'dataset'\n",
    "command = 'aws s3 sync --no-sign-request s3://openneuro.org/ds002014 ' + TARGET_DIR\n",
    "command = command.split(' ')\n",
    "if subprocess.call(command) == 0:\n",
    "    print(\"Dataset successfully downloaded\")\n",
    "else:\n",
    "    print(\"Error in calling download command\")\n",
    "    \n",
    "\n",
    "\"\"\" Open downloaded dataset \"\"\"\n",
    "from rtCommon.bidsArchive import BidsArchive\n",
    "\n",
    "archive = BidsArchive(TARGET_DIR)\n",
    "print('Archive: ', archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Archive: Querying Dataset\n",
    "\n",
    "Objective: Learn how to extract information and files from the `BidsArchive`.\n",
    "\n",
    "Procedure:\n",
    "\n",
    "1. Search for images in the dataset.\n",
    "2. Search for sidecar metadata for the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Any BIDS entity can be extracted from the archive using getEntity() (e.g., getSubjects(), getRuns(), getTasks())\n",
    "print('Dataset info: Subjects: {subjects} | Runs: {runs} | Tasks: {tasks}\\n'\n",
    "      .format(subjects=archive.getSubjects(), runs=archive.getRuns(), tasks=archive.getTasks()))\n",
    "\n",
    "# Arguments can be passed as keywords or using a dictionary with equivalent results\n",
    "entityDict = {'subject': archive.getSubjects()[0], 'run': archive.getRuns()[0]}\n",
    "imagesUsingDict = archive.getImages(**entityDict)\n",
    "imagesUsingKeywords = archive.getImages(subject=archive.getSubjects()[0], run=archive.getRuns()[0])\n",
    "assert imagesUsingDict == imagesUsingKeywords\n",
    "\n",
    "print('Number of image files associated with Subject {}, Run {}: {}'.format(\n",
    "    entityDict['subject'], entityDict['run'], len(imagesUsingDict)))\n",
    "\n",
    "# Get all images from the functional runs\n",
    "images = archive.getImages(datatype='func')\n",
    "print('Number of functional images: {}'.format(len(images)))\n",
    "\n",
    "# Anatomical images can be retrieved too\n",
    "images = archive.getImages(datatype='anat')\n",
    "print('Number of anatomical images: {}'.format(len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No images are returned if matches aren't found\n",
    "subjectName='invalidSubject'\n",
    "images = archive.getImages(subject=subjectName)\n",
    "print('Number of image files associated with Subject \"{}\": {}'.format(subjectName, len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to get images from an archive, we'll look at how to get metadata for images we've retrieved from the archive.\n",
    "\n",
    "To get metadata for an image, the path to the image file is required. Every `BIDSImageFile` returned from `getImages` has a `path` property you can use to obtain this path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Get all image files, then create a dictionary mapping each image file's path to its metadata dictionary\n",
    "imageFiles = archive.getImages()\n",
    "metadata = {i.path: archive.getMetadata(i.path) for i in imageFiles}\n",
    "for path, metaDict in metadata.items():\n",
    "    print('Metadata for:', path, \"is:\\n\", json.dumps(metaDict, indent=4, sort_keys=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece of data we'll see how to get from an archive is the events file corresponding to a particular scanning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event files to get can be filtered by entities, as with \n",
    "# getImages and getMetadata\n",
    "events = archive.getEvents(subject='01', \n",
    "                           task='languageproduction', run=1)\n",
    "\n",
    "# All event files can be retrieved when specifiying no entities\n",
    "events = archive.getEvents()\n",
    "\n",
    "# Event files are returned as BIDSDataFile objects\n",
    "# See the PyBids documentation for more information on those\n",
    "eventsFile = events[0]\n",
    "print('Events file type: ', type(eventsFile))\n",
    "\n",
    "# One method of the BIDSDataFile object returns\n",
    "# a Pandas data frame of the events file\n",
    "eventsDF = eventsFile.get_df()\n",
    "\n",
    "print(\"Sample data: \\n\", eventsDF[:][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Archive: Getting & Appending Incrementals\n",
    "\n",
    "One of the most important functions that a BIDS Archive enables in the context of RT-Cloud is working with BIDS Incrementals. Using a BIDS Archive, you can extract data and package it into a BIDS Incremental using `getIncremental`, and you can append new data in BIDS Incrementals to the archive using `appendIncremental`.\n",
    "\n",
    "For example, if you have a complete dataset that you want to test a new real-time experiment on, you can using `getIncremental` repeatedly to iterate over your entire dataset, streaming the resulting BIDS Incrementals to RT-Cloud and the new experimental script you want to try out. Then, when you're running your new experiment in RT-Cloud for real, as BIDS Incremental files are streamed from the scanner to your script, you can build up an archive of your entire experiment by calling `appendIncremental` for each BIDS Incremental you receive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an archive and get an incremental\n",
    "firstIncremental = archive.getIncremental(subject='01', task='languageproduction')\n",
    "\n",
    "# Iterate through each time slice of the 4-D NIfTI file and \n",
    "# store the incrementals in order\n",
    "entityFilterDict = {'subject': '01', 'task': 'languageproduction'}\n",
    "NUM_SLICES = firstIncremental.imageDimensions[3]\n",
    "incrementals = []\n",
    "for i in range(NUM_SLICES):\n",
    "    incrementals.append(archive.getIncremental(**entityFilterDict))\n",
    "    \n",
    "# Append them in the same order as they were retrieved to a new archive,\n",
    "# then show that the two archives have the same data for that subject & task\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as td:\n",
    "    # Create new archive\n",
    "    newArchive = BidsArchive(td)\n",
    "    for inc in incrementals:\n",
    "        newArchive.appendIncremental(inc)\n",
    "        \n",
    "    # Compare incrementals in original and new archive\n",
    "    for i in range(NUM_SLICES):\n",
    "        assert archive.getIncremental(**entityFilterDict) == \\\n",
    "               newArchive.getIncremental(**entityFilterDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Creating Incremental\n",
    "\n",
    "A `BIDS Incremental` has two primary components:\n",
    "1. A NIfTI image\n",
    "2. A metadata dictionary storing information about the image.\n",
    "\n",
    "It also has a few other components that are used when the `BIDS Incremental` is written to disk, and may be used by you for other purposes. Those are:\n",
    "1. The dataset description dictionary, which becomes the `dataset_description.json` in a BIDS Archive.\n",
    "2. The README string, which becomes the `README` file in a BIDS archive.\n",
    "3. The events dataframe, which becomes the `<file name entities>_events.tsv` file in a BIDS archive.\n",
    "\n",
    "To create a `BIDS Incremental`, only the image and the metadata dictionary are needed, and default versions of the other components are created if the `BIDS Incremental` is written to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading from a BIDS-compliant dataset, all metadata\n",
    "should already be present, and using BIDS Archive methods\n",
    "to read the image and metadata is sufficient to create the\n",
    "incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rtCommon.bidsIncremental import BidsIncremental\n",
    "\n",
    "# Get the NIfTI image\n",
    "imageFile = archive.getImages(subject='01', run=1)[0]\n",
    "image = imageFile.get_image()\n",
    "\n",
    "# Get the metadata for the image\n",
    "metadata = archive.getMetadata(imageFile.path)\n",
    "\n",
    "# Create the BIDS Incremental\n",
    "incremental = BidsIncremental(image, metadata)\n",
    "print('Created Incremental: ', incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If converting from a DICOM image, sometimes extra work on metadata is needed. This is because BIDS requires certain fields in order to build a valid archive, so BIDS Incremental requires that these fields be provided at creation time in the metadata dictionary. The following example shows how these fields sometimes must be added by the user of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtCommon.imageHandling import convertDicomFileToNifti, readDicomFromFile, readNifti\n",
    "from rtCommon.bidsCommon import getDicomMetadata\n",
    "from rtCommon.errors import MissingMetadataError\n",
    "\n",
    "with tempfile.TemporaryDirectory() as td:\n",
    "    TEMP_NIFTI_NAME = 'temp.nii'\n",
    "    TEMP_NIFTI_PATH = os.path.join(td, TEMP_NIFTI_NAME)\n",
    "    dicomPath = os.path.join(rootPath, \"tests/test_input/001_000013_000005.dcm\")\n",
    "    convertDicomFileToNifti(dicomPath, TEMP_NIFTI_PATH)\n",
    "    image = readNifti(TEMP_NIFTI_PATH)\n",
    "\n",
    "    publicMeta, privateMeta = getDicomMetadata(readDicomFromFile(dicomPath))\n",
    "    publicMeta.update(privateMeta)\n",
    "\n",
    "    try:\n",
    "        incremental = BidsIncremental(image, publicMeta)\n",
    "    except MissingMetadataError as e:\n",
    "        print(e)\n",
    "        # We can see that 'subject', 'suffix', and 'datatype' were not \n",
    "        # in the metadata able to be extracted from the DICOM; thus, we'll\n",
    "        # have to provide them manually based on our knowledge of the experiment\n",
    "\n",
    "    # Here, we'll pretend the subject is the 1st subject, the imaging methodology\n",
    "    # was fMRI BOLD, and the datatype is func, representing a functional run\n",
    "    publicMeta.update({'subject': '01', 'suffix': 'bold', 'datatype': 'func'})\n",
    "\n",
    "    # Now, the incremental's creation will succeed\n",
    "    incremental = BidsIncremental(image, publicMeta)\n",
    "    print('Created Incremental:', incremental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Querying Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `BIDS Incremental` is the basic unit of data transfer in RT-Cloud, and your scripts will often interact directly with an Incremental and the data within it. This part of the tutorial will show you how to obtain different parts of the Incremental's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting, setting, and removing metadata\n",
    "fields = ['subject', 'task', 'RepetitionTime', 'ProtocolName']\n",
    "print('-------- Getting Fields --------')\n",
    "for field in fields:\n",
    "    print(field + ': ' + str(incremental.getMetadataField(field)))\n",
    "    \n",
    "print('\\n-------- After Setting Fields --------')\n",
    "for field in fields:\n",
    "    incremental.setMetadataField(field, 'test')\n",
    "for field in fields:\n",
    "    print(field + ': ' + str(incremental.getMetadataField(field)))\n",
    "    \n",
    "print('\\n-------- Removing Fields --------')\n",
    "for field in fields:\n",
    "    # Note that required fields can only be changed, not removed\n",
    "    try:\n",
    "        incremental.removeMetadataField(field)\n",
    "    except ValueError as e:\n",
    "        print(str(e))\n",
    "for field in fields:\n",
    "    print(field + ': ' + str(incremental.getMetadataField(field)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\n-------- Full Metadata Dictionary --------')\n",
    "print(incremental.imageMetadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to these methods, there are several properties that help extract particular entities or data having to do with the NIfTI image contained within the Incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities\n",
    "print('Suffix:', incremental.suffix)\n",
    "print('Datatype:', incremental.datatype)\n",
    "print('BIDS Entities:', incremental.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image properties\n",
    "print('Image dimensions:', incremental.imageDimensions)\n",
    "print('\\nImage header:', incremental.imageHeader)\n",
    "print('\\nImage data:', incremental.imageData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each `BIDS Incremental` can also be made into a fully valid, on-disk BIDS Archive, there are also a variety of properties in the `BIDS Incremental` about how its data would be represented on disk in folders and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n-------- Directory Names and Paths --------')\n",
    "print('Dataset directory name:', incremental.datasetName)\n",
    "print('Data directory path:', incremental.dataDirPath)\n",
    "\n",
    "print('\\n-------- File Names --------')\n",
    "print('Image file name:', incremental.imageFileName)\n",
    "print('Metadata file name:', incremental.metadataFileName)\n",
    "print('Events file name:', incremental.eventsFileName)\n",
    "\n",
    "print('\\n-------- File Paths --------')\n",
    "print('Image file path:', incremental.imageFilePath)\n",
    "print('Metadata file path:', incremental.metadataFilePath)\n",
    "print('Events file path:', incremental.eventsFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Writing to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key features of a `BIDS Incremental` is that it is also a valid, 1-image `BIDS Archive`. Thus, a `BIDS Incremental` can be written out to an archive on disk and navigated on the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive: Root: ...61t76xtwh00000gn/T/tmpa3rpi9b5 | Subjects: 1 | Sessions: 1 | Runs: 1\n",
      "\n",
      "BIDS Files in Archive from Incremental: [<BIDSJSONFile filename='/var/folders/3j/db49krhd0sq5n961t76xtwh00000gn/T/tmpa3rpi9b5/dataset_description.json'>, <BIDSFile filename='/var/folders/3j/db49krhd0sq5n961t76xtwh00000gn/T/tmpa3rpi9b5/README'>, <BIDSJSONFile filename='/var/folders/3j/db49krhd0sq5n961t76xtwh00000gn/T/tmpa3rpi9b5/sub-test/ses-01/func/sub-test_ses-01_task-test_run-1_bold.json'>, <BIDSImageFile filename='/var/folders/3j/db49krhd0sq5n961t76xtwh00000gn/T/tmpa3rpi9b5/sub-test/ses-01/func/sub-test_ses-01_task-test_run-1_bold.nii'>, <BIDSDataFile filename='/var/folders/3j/db49krhd0sq5n961t76xtwh00000gn/T/tmpa3rpi9b5/sub-test/ses-01/func/sub-test_ses-01_task-test_run-1_events.tsv'>]\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as td:\n",
    "    incremental.writeToArchive(td)\n",
    "\n",
    "    archiveFromIncremental = BidsArchive(td)\n",
    "    print('Archive:', archiveFromIncremental)\n",
    "    print('\\nBIDS Files in Archive from Incremental:', archiveFromIncremental.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Sending Over a Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rtcloud] *",
   "language": "python",
   "name": "conda-env-rtcloud-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
