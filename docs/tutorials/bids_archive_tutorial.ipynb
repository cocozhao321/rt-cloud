{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook teaches how to use the BIDS Archive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "There are a few terms that are important to understand before starting to use BIDS Archive.\n",
    "\n",
    "## BIDS Entities\n",
    "\n",
    "BIDS Entities, referred to later as just 'entities', represent metadata about files in the archive. You may already be familiar with common ones, like 'subject', 'task', and 'run'. \n",
    "\n",
    "Most entities are used in a key-value form and have their name and value present wherever they are used. They have three main representations. The first is the entity itself, the one-word, all lowercase string (e.g., 'subject'). The second is the entity's name, which may be sevearl words (e.g., 'Contrast Enhancing Agent' is the name for the 'ceagent' entity). The third is the entity's key, which is typically shorter and used in file names (e.g., 'ce' for the 'ceagent' entity). A few entities and their multiple representations are shown in the table below:\n",
    "\n",
    "| Entity | Name | Key |\n",
    "| --- | --- | --- |\n",
    "| subject | Subject | sub |\n",
    "| session | Session | ses |\n",
    "| run | Run | run |\n",
    "| ceagent | Contrast Enhancing Agent | ce |\n",
    "\n",
    "Some entities aren't used in key-value format, and have only one representation. Examples include 'datatype' (e.g., 'func' or 'anat'), 'extension' (e.g., '.nii', '.nii.gz', or '.json'), and 'suffix' (e.g., 'bold'). See the table below for how these can appear in file naming and archive organization.\n",
    "\n",
    "Together, these entities provide a unique and consistent way to name files and organize the BIDS dataset.\n",
    "\n",
    "#### Exercise: What entities are present in the path `sub-01/func/sub-01_task-languageproduction_run-01_bold.nii.gz`, and what are the entity values? \n",
    "\n",
    "##### Answer: \n",
    "| Entity Name | Value |\n",
    "|---          | ---   |\n",
    "| subject | 01 |\n",
    "| datatype | func |\n",
    "| task | languageproduction |\n",
    "| run | 01 |\n",
    "| suffix | bold |\n",
    "| extension | .nii.gz|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Archive: Opening Existing Dataset\n",
    "\n",
    "Objective: Learn how to create a BIDS Archive pointing to a specific dataset on disk.\n",
    "\n",
    "Procedure:\n",
    "1. Download a small, sample dataset from OpenNeuro to use with `BidsArchive`.\n",
    "2. Open the dataset using `BidsArchive` and print out some summary data about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully downloaded\n",
      "Archive:  Root: ...t-cloud/docs/tutorials/dataset | Subjects: 1 | Sessions: 0 | Runs: 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Add rtCommon to the path \"\"\"\n",
    "import os\n",
    "import sys\n",
    "currPath = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "rootPath = os.path.dirname(currPath)\n",
    "sys.path.append(rootPath)\n",
    "\n",
    "\n",
    "\"\"\" Download the dataset \"\"\"\n",
    "import subprocess\n",
    "\n",
    "# https://openneuro.org/datasets/ds002014/versions/1.0.1/download -- <40MB dataset\n",
    "TARGET_DIR = 'dataset'\n",
    "command = 'aws s3 sync --no-sign-request s3://openneuro.org/ds002014 ' + TARGET_DIR\n",
    "command = command.split(' ')\n",
    "if subprocess.call(command) == 0:\n",
    "    print(\"Dataset successfully downloaded\")\n",
    "else:\n",
    "    print(\"Error in calling download command\")\n",
    "    \n",
    "\n",
    "\"\"\" Open downloaded dataset \"\"\"\n",
    "from rtCommon.bidsArchive import BidsArchive\n",
    "\n",
    "archive = BidsArchive(TARGET_DIR)\n",
    "print('Archive: ', archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Archive: Querying Dataset\n",
    "\n",
    "Objective: Learn how to extract information and files from the `BidsArchive`.\n",
    "\n",
    "Procedure:\n",
    "\n",
    "1. Search for images in the dataset.\n",
    "2. Search for sidecar metadata for the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info: Subjects: ['01'] | Runs: [1] | Tasks: ['languageproduction']\n",
      "\n",
      "Number of image files associated with Subject 01, Run 1: 1\n",
      "Number of functional images: 1\n",
      "Number of anatomical images: 1\n"
     ]
    }
   ],
   "source": [
    "# Any BIDS entity can be extracted from the archive using getEntity() (e.g., getSubjects(), getRuns(), getTasks())\n",
    "print('Dataset info: Subjects: {subjects} | Runs: {runs} | Tasks: {tasks}\\n'\n",
    "      .format(subjects=archive.getSubjects(), runs=archive.getRuns(), tasks=archive.getTasks()))\n",
    "\n",
    "# Arguments can be passed as keywords or using a dictionary with equivalent results\n",
    "entityDict = {'subject': archive.getSubjects()[0], 'run': archive.getRuns()[0]}\n",
    "imagesUsingDict = archive.getImages(**entityDict)\n",
    "imagesUsingKeywords = archive.getImages(subject=archive.getSubjects()[0], run=archive.getRuns()[0])\n",
    "assert imagesUsingDict == imagesUsingKeywords\n",
    "\n",
    "print('Number of image files associated with Subject {}, Run {}: {}'.format(\n",
    "    entityDict['subject'], entityDict['run'], len(imagesUsingDict)))\n",
    "\n",
    "# Get all images from the functional runs\n",
    "images = archive.getImages(datatype='func')\n",
    "print('Number of functional images: {}'.format(len(images)))\n",
    "\n",
    "# Anatomical images can be retrieved too\n",
    "images = archive.getImages(datatype='anat')\n",
    "print('Number of anatomical images: {}'.format(len(images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:rtCommon.bidsArchive:No images have all provided entities: {'subject': 'invalidSubject'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files associated with Subject \"invalidSubject\": 0\n"
     ]
    }
   ],
   "source": [
    "# No images are returned if matches aren't found\n",
    "subjectName='invalidSubject'\n",
    "images = archive.getImages(subject=subjectName)\n",
    "print('Number of image files associated with Subject \"{}\": {}'.format(subjectName, len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to get images from an archive, we'll look at how to get metadata for images we've retrieved from the archive.\n",
    "\n",
    "To get metadata for an image, the path to the image file is required. Every `BIDSImageFile` returned from `getImages` has a `path` property you can use to obtain this path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for: /Users/stephen/Documents/princeton/fall2020/cos4978 thesis/rt-cloud/docs/tutorials/dataset/sub-01/anat/sub-01_T1w.nii.gz is:\n",
      " {\n",
      "    \"AcquisitionMatrixPE\": 320,\n",
      "    \"AcquisitionNumber\": 1,\n",
      "    \"AcquisitionTime\": \"16:23:42.600000\",\n",
      "    \"ConversionSoftware\": \"dcm2niix\",\n",
      "    \"ConversionSoftwareVersion\": \"v1.0.20190410  GCC4.8.2\",\n",
      "    \"DeviceSerialNumber\": \"40720\",\n",
      "    \"EchoTime\": 0.0025,\n",
      "    \"FlipAngle\": 9,\n",
      "    \"ImageOrientationPatientDICOM\": [\n",
      "        0.998291,\n",
      "        0.0584448,\n",
      "        0.000264799,\n",
      "        -0.0340637,\n",
      "        0.58551,\n",
      "        -0.809949\n",
      "    ],\n",
      "    \"ImageType\": [\n",
      "        \"DERIVED\",\n",
      "        \"SECONDARY\",\n",
      "        \"MPR\",\n",
      "        \"CSA\",\n",
      "        \"MPR\",\n",
      "        \"CSAPARALLEL\",\n",
      "        \"M\",\n",
      "        \"ND\",\n",
      "        \"NORM\"\n",
      "    ],\n",
      "    \"ImagingFrequency\": 123.188,\n",
      "    \"InPlanePhaseEncodingDirectionDICOM\": \"ROW\",\n",
      "    \"InstitutionAddress\": \"Maraweg_21_Bielefeld_District_DE_33617\",\n",
      "    \"InstitutionName\": \"EVKB_Mara_1\",\n",
      "    \"InstitutionalDepartmentName\": \"Department\",\n",
      "    \"InversionTime\": 0.9,\n",
      "    \"MRAcquisitionType\": \"3D\",\n",
      "    \"MagneticFieldStrength\": 3,\n",
      "    \"Manufacturer\": \"Siemens\",\n",
      "    \"ManufacturersModelName\": \"Verio\",\n",
      "    \"Modality\": \"MR\",\n",
      "    \"PatientPosition\": \"HFS\",\n",
      "    \"PercentPhaseFOV\": 100,\n",
      "    \"PhaseEncodingSteps\": 349,\n",
      "    \"PixelBandwidth\": 180,\n",
      "    \"ProtocolName\": \"t1_mpr_sag_p2_iso0_9_320_:-)\",\n",
      "    \"RawImage\": true,\n",
      "    \"ReconMatrixPE\": 320,\n",
      "    \"RepetitionTime\": 1.9,\n",
      "    \"SAR\": 0.0566637,\n",
      "    \"ScanOptions\": \"IR_PFP\",\n",
      "    \"ScanningSequence\": \"GR_IR\",\n",
      "    \"SequenceName\": \"_tfl3d1_ns\",\n",
      "    \"SequenceVariant\": \"SP_MP_OSP\",\n",
      "    \"SeriesDescription\": \"<MPR-Modus_Serie[1]>\",\n",
      "    \"SeriesNumber\": 13,\n",
      "    \"SliceThickness\": 0.8,\n",
      "    \"SoftwareVersions\": \"syngo_MR_B19\",\n",
      "    \"StationName\": \"MRC40720\",\n",
      "    \"datatype\": \"anat\",\n",
      "    \"extension\": \".nii.gz\",\n",
      "    \"subject\": \"01\",\n",
      "    \"suffix\": \"T1w\"\n",
      "} \n",
      "\n",
      "Metadata for: /Users/stephen/Documents/princeton/fall2020/cos4978 thesis/rt-cloud/docs/tutorials/dataset/sub-01/func/sub-01_task-languageproduction_run-01_bold.nii.gz is:\n",
      " {\n",
      "    \"AcquisitionMatrixPE\": 64,\n",
      "    \"AcquisitionNumber\": 1,\n",
      "    \"AcquisitionTime\": \"16:34:34.400000\",\n",
      "    \"BandwidthPerPixelPhaseEncode\": 30.637,\n",
      "    \"BaseResolution\": 64,\n",
      "    \"CoilString\": \"t:HEA;HEP\",\n",
      "    \"ConversionSoftware\": \"dcm2niix\",\n",
      "    \"ConversionSoftwareVersion\": \"v1.0.20190410  GCC4.8.2\",\n",
      "    \"DelayTime\": 1.2,\n",
      "    \"DerivedVendorReportedEchoSpacing\": 0.000510004,\n",
      "    \"DeviceSerialNumber\": \"40720\",\n",
      "    \"DwellTime\": 3.5e-06,\n",
      "    \"EchoTime\": 0.05,\n",
      "    \"EffectiveEchoSpacing\": 0.000510004,\n",
      "    \"FlipAngle\": 90,\n",
      "    \"ImageOrientationPatientDICOM\": [\n",
      "        0.999651,\n",
      "        0.00349064,\n",
      "        0.0261768,\n",
      "        -0.00348945,\n",
      "        0.999994,\n",
      "        -9.13743e-05\n",
      "    ],\n",
      "    \"ImageType\": [\n",
      "        \"ORIGINAL\",\n",
      "        \"PRIMARY\",\n",
      "        \"FMRI\",\n",
      "        \"NONE\",\n",
      "        \"ND\",\n",
      "        \"MOSAIC\"\n",
      "    ],\n",
      "    \"ImagingFrequency\": 123.188,\n",
      "    \"InPlanePhaseEncodingDirectionDICOM\": \"COL\",\n",
      "    \"InstitutionAddress\": \"Maraweg_21_Bielefeld_District_DE_33617\",\n",
      "    \"InstitutionName\": \"EVKB_Mara_1\",\n",
      "    \"InstitutionalDepartmentName\": \"Department\",\n",
      "    \"MRAcquisitionType\": \"2D\",\n",
      "    \"MagneticFieldStrength\": 3,\n",
      "    \"Manufacturer\": \"Siemens\",\n",
      "    \"ManufacturersModelName\": \"Verio\",\n",
      "    \"Modality\": \"MR\",\n",
      "    \"PartialFourier\": 1,\n",
      "    \"PatientPosition\": \"HFS\",\n",
      "    \"PercentPhaseFOV\": 100,\n",
      "    \"PhaseEncodingDirection\": \"j-\",\n",
      "    \"PhaseEncodingSteps\": 64,\n",
      "    \"PhaseResolution\": 1,\n",
      "    \"PixelBandwidth\": 2232,\n",
      "    \"ProcedureStepDescription\": \"Mara_12CH_fMRT\",\n",
      "    \"ProtocolName\": \"ep2d_bold_moco_5mm_Sprache_(pace)\",\n",
      "    \"PulseSequenceDetails\": \"%SiemensSeq%_ep2d_pace\",\n",
      "    \"ReceiveCoilName\": \"HeadMatrix\",\n",
      "    \"ReconMatrixPE\": 64,\n",
      "    \"RepetitionTime\": 3,\n",
      "    \"SAR\": 0.0330235,\n",
      "    \"ScanOptions\": \"FS\",\n",
      "    \"ScanningSequence\": \"EP\",\n",
      "    \"SequenceName\": \"_epfid2d1_64\",\n",
      "    \"SequenceVariant\": \"SK\",\n",
      "    \"SeriesDescription\": \"ep2d_bold_moco_5mm_Sprache_(pace)\",\n",
      "    \"SeriesNumber\": 6,\n",
      "    \"ShimSetting\": [\n",
      "        7400,\n",
      "        11362,\n",
      "        -12012,\n",
      "        138,\n",
      "        -140,\n",
      "        460,\n",
      "        385,\n",
      "        -228\n",
      "    ],\n",
      "    \"SliceThickness\": 5,\n",
      "    \"SliceTiming\": [\n",
      "        0,\n",
      "        0.935,\n",
      "        0.085,\n",
      "        1.02,\n",
      "        0.17,\n",
      "        1.105,\n",
      "        0.255,\n",
      "        1.19,\n",
      "        0.34,\n",
      "        1.275,\n",
      "        0.425,\n",
      "        1.36,\n",
      "        0.51,\n",
      "        1.445,\n",
      "        0.595,\n",
      "        1.53,\n",
      "        0.68,\n",
      "        1.615,\n",
      "        0.765,\n",
      "        1.7,\n",
      "        0.85\n",
      "    ],\n",
      "    \"SoftwareVersions\": \"syngo_MR_B19\",\n",
      "    \"SpacingBetweenSlices\": 5,\n",
      "    \"StationName\": \"MRC40720\",\n",
      "    \"TaskName\": \"language production task, semantic fluency\",\n",
      "    \"TotalReadoutTime\": 0.0321303,\n",
      "    \"TxRefAmp\": 400.793,\n",
      "    \"datatype\": \"func\",\n",
      "    \"extension\": \".nii.gz\",\n",
      "    \"run\": 1,\n",
      "    \"subject\": \"01\",\n",
      "    \"suffix\": \"bold\",\n",
      "    \"task\": \"languageproduction\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Get all image files, then create a dictionary mapping each image file's path to its metadata dictionary\n",
    "imageFiles = archive.getImages()\n",
    "metadata = {i.path: archive.getMetadata(i.path) for i in imageFiles}\n",
    "for path, metaDict in metadata.items():\n",
    "    print('Metadata for:', path, \"is:\\n\", json.dumps(metaDict, indent=4, sort_keys=True), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece of data we'll see how to get from an archive is the events file corresponding to a particular scanning run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events file type:  <class 'bids.layout.models.BIDSDataFile'>\n",
      "Sample data: \n",
      "    onset  duration   trial_type\n",
      "0      0        30         rest\n",
      "1     30        30  occupations\n",
      "2     60        30         rest\n",
      "3     90        30      animals\n",
      "4    120        30         rest\n"
     ]
    }
   ],
   "source": [
    "# Event files to get can be filtered by entities, as with \n",
    "# getImages and getMetadata\n",
    "events = archive.getEvents(subject='01', \n",
    "                           task='languageproduction', run=1)\n",
    "\n",
    "# All event files can be retrieved when specifiying no entities\n",
    "events = archive.getEvents()\n",
    "\n",
    "# Event files are returned as BIDSDataFile objects\n",
    "# See the PyBids documentation for more information on those\n",
    "eventsFile = events[0]\n",
    "print('Events file type: ', type(eventsFile))\n",
    "\n",
    "# One method of the BIDSDataFile object returns\n",
    "# a Pandas data frame of the events file\n",
    "eventsDF = eventsFile.get_df()\n",
    "\n",
    "print(\"Sample data: \\n\", eventsDF[:][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Archive: Getting & Appending Incrementals\n",
    "\n",
    "One of the most important functions that a BIDS Archive enables in the context of RT-Cloud is working with BIDS Incrementals. Using a BIDS Archive, you can extract data and package it into a BIDS Incremental using `getIncremental`, and you can append new data in BIDS Incrementals to the archive using `appendIncremental`.\n",
    "\n",
    "For example, if you have a complete dataset that you want to test a new real-time experiment on, you can using `getIncremental` repeatedly to iterate over your entire dataset, streaming the resulting BIDS Incrementals to RT-Cloud and the new experimental script you want to try out. Then, when you're running your new experiment in RT-Cloud for real, as BIDS Incremental files are streamed from the scanner to your script, you can build up an archive of your entire experiment by calling `appendIncremental` for each BIDS Incremental you receive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an archive and get an incremental\n",
    "firstIncremental = archive.getIncremental(subject='01', task='languageproduction')\n",
    "\n",
    "# Iterate through each time slice of the 4-D NIfTI file and \n",
    "# store the incrementals in order\n",
    "entityFilterDict = {'subject': '01', 'task': 'languageproduction'}\n",
    "NUM_SLICES = firstIncremental.imageDimensions[3]\n",
    "incrementals = []\n",
    "for i in range(NUM_SLICES):\n",
    "    incrementals.append(archive.getIncremental(**entityFilterDict))\n",
    "    \n",
    "# Append them in the same order as they were retrieved to a new archive,\n",
    "# then show that the two archives have the same data for that subject & task\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as td:\n",
    "    # Create new archive\n",
    "    newArchive = BidsArchive(td)\n",
    "    for inc in incrementals:\n",
    "        newArchive.appendIncremental(inc)\n",
    "        \n",
    "    # Compare incrementals in original and new archive\n",
    "    for i in range(NUM_SLICES):\n",
    "        assert archive.getIncremental(**entityFilterDict) == \\\n",
    "               newArchive.getIncremental(**entityFilterDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Creating Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Querying Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Writing to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Incremental: Sending Over a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rtcloud] *",
   "language": "python",
   "name": "conda-env-rtcloud-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
